echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=false gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=philschmid/MiniLM-L6-H384-uncased-sst2
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8 -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=false gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=philschmid/MiniLM-L6-H384-uncased-sst2
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8 -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=false gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=philschmid/MiniLM-L6-H384-uncased-sst2
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8 -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=true gpu_fp16=true cpu= optimizer=true batch=1 sequence= models=philschmid/MiniLM-L6-H384-uncased-sst2
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=true gpu_fp16=true cpu= optimizer=true batch=1 sequence= models=philschmid/MiniLM-L6-H384-uncased-sst2
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -p fp16
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -p fp16 -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -p fp16
echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=true gpu_fp16=true cpu= optimizer=true batch=1 sequence= models=philschmid/MiniLM-L6-H384-uncased-sst2
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -p fp16
python -m onnxruntime.transformers.benchmark -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -p fp16 -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m philschmid/MiniLM-L6-H384-uncased-sst2 -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -p fp16
echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=true gpu_fp16=true cpu= optimizer=true batch=1 sequence= models=microsoft/MiniLM-L12-H384-uncased
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=false gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=microsoft/MiniLM-L12-H384-uncased
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8 -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=false gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=microsoft/MiniLM-L12-H384-uncased
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8 -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=false gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=microsoft/MiniLM-L12-H384-uncased
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
echo ort=true torch=false torchscript=true tensorflow=false gpu_fp32=false gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=bert-large-uncased microsoft/MiniLM-L12-H384-uncased
python -m onnxruntime.transformers.benchmark -m bert-large-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m bert-large-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m bert-large-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m bert-large-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
python -m onnxruntime.transformers.benchmark -m bert-large-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8 -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m bert-large-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8 -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -p int8
echo ort=true torch=false torchscript=true tensorflow=true gpu_fp32=false gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=microsoft/MiniLM-L12-H384-uncased
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -e tensorflow -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
echo ort=true torch=false torchscript=true tensorflow=true gpu_fp32=false gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=microsoft/MiniLM-L12-H384-uncased
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -e tensorflow -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 16 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
echo ort=true torch=false torchscript=true tensorflow=true gpu_fp32=false gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=microsoft/MiniLM-L12-H384-uncased
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
python -m onnxruntime.transformers.benchmark -e tensorflow -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 128 -t 100 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o
echo ort=true torch=false torchscript=true tensorflow=true gpu_fp32=true gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=microsoft/MiniLM-L12-H384-uncased
echo ort=true torch=false torchscript=true tensorflow=true gpu_fp32=true gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=microsoft/MiniLM-L12-H384-uncased
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
python -m onnxruntime.transformers.benchmark -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
python -m onnxruntime.transformers.benchmark -e tensorflow -m microsoft/MiniLM-L12-H384-uncased -b 1 -s 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
echo ort=true torch=false torchscript=true tensorflow=true gpu_fp32=true gpu_fp16=false cpu= optimizer=true batch=1 sequence= models=gpt2
python -m onnxruntime.transformers.benchmark -m gpt2 -i 1 -v -b 0 --overwrite -f fusion.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
python -m onnxruntime.transformers.benchmark -m gpt2 -b 1 -s 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g -i 1
python -m onnxruntime.transformers.benchmark -e torchscript -m gpt2 -b 1 -s 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
python -m onnxruntime.transformers.benchmark -e tensorflow -m gpt2 -b 1 -s 128 -t 1000 -f fusion.csv -r result.csv -d detail.csv -c ./cache_models --onnx_dir ./onnx_models -o -g
